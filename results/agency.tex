%Preamble
\documentclass[12pt]{article}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{commath}

\theoremstyle{definition}
\newtheorem{defn}{Definition}
\newtheorem{conj}{Conjecture}
\newtheorem{cor}{Corollary}
\newtheorem{lem}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{prf}{Proof}

%Body
\begin{document}

\title{A Theory of Embeded Agency}
\author{Ben Reis\footnote{Imperfectly educated layman; embeded agent}}
\maketitle

\section{Introduction}
Much hay has been made over the hypothetical powers of artificial general
intelligence. In particular, a number of organizations and researchers have come
to endorse the position that a ``superintelligent'' AI will be constructed at
some point in the near future, and that measures must be taken to ensure that
said AI is ``friendly'', ie not likely to cause significant harm to humanity as
a whole.

The urgency of this task depends on the idea that ``intelligence'' is a
fundamentally unbounded property. That is, there is no maximally intelligent
mind and there exists a mind capable of constructing other minds that share its
goals but are more intelligent. The nature of the task depends on the current
nonexistence of any sort of superintelligent AI and on the particular presumed
form of any superintelligence that will emerge in the future, namely that such
an intelligence (and any successors it creates) will be a single computer
program, or possibly many copies of a single program, implimented on a direct
physical substrate.

However, at least as far as I can tell, relatively little work has been done to
check these assumptions. This is partially because of a difficulty in definition
- the fact that an agent must be embeded within the universe on which it acts
makes it difficult to rigorously define the problems an agent faces, and thence
prove limits on an agent's ability to solve them. In this paper I primarily wish
to define agency within a universe that has properties allowing the generated
results to apply to agents in the real world, without specifying the physics of
that universe more than necessary.

The definitions and results presented here, and any consequences thereof, I call
the theory of embeded agency. Embeded agency touches on a wide range of topics;
results from physics, game theory, decision theory, signal processing, social
choice theory, and classical machine learning and AI studies are likely to be
useful in studying this field. My hope is to provide a framework for
synthesizing these results into a realistic model of agency as it can be
implemented in the real world.

\section{The Universe and its Properties}
\label{sec:universe}

We begin by defining the universe in which our agent will act. This will be
where most of our assumptions are located; the applicability of the results in
this paper depends on the defined universe matching up to our own as to the
effects of its properties on the capabilities of an agent embeded within it. I
will occasionally refer in this section to the agent or agents embeded within
the universe; these will be defined in Section \ref{sec:agents}.

The first and most fundamental assumption is that the universe is a universal
Turing machine or Turing equivalent construct - that is, a mathematical
construct capable of simulating Turing machines - but \textit{not} a more
powerful construct such as a hypercomputer, and not a construct with distinct
capabilities like a real computer\footnote{That the universe is not a real
computer depends on the holographic principle being a physical law. This is
widely suspected but not confirmed, and would forbid certain solutions to
general relativity, the implications of which are an unsolved problem in quantum
gravity.}. In the remainder of this section, I will examine a classical Turing
machine\footnote{5-tuple, two-way tape model; all instructions must move one
space left or right. Other models complicate some of the locality-related
notions discussed below.} and a Turing complete cellular automaton and determine
how these classes must be restricted, if necessary, to conform to our remaining
axiomatic properties. I find the cellular automaton's conformance to the axioms
to be more intuitive\footnotemark, but it may be easier to prove properties of
agents with respect to a Turing machine universe. The violation of these axioms
will be addressed briefly below but are not a focus of this paper.

\footnotetext{In general I find the intuitive conformance of cellular automata
to certain axioms of physics, and the existance of \textit{Day and Night}, a
Life-like rule that appears to exhibit a kind of charge symmetry, to be highly
suggestive in a physics context, but I lack the background to effectively
examine the implications. \cite{moriceau2011}, \cite{wacker2016}, and the works
they cite appear to be useful places to start when examining the idea of a
cellular automaton (perhaps somewhat generalized) that generates known laws of
physics.}

Second, we assume that the universe is deterministic. This is largely to
simplify certain ideas discussed in Section \ref{sec:models}, but the
implications of a nondeterministic universe should be examined at some
point.\footnote{For one thing, in a deterministic universe, it is trivial as a
practical matter that \(P \not= \mathit{NP}\), since nondeterministic machines
cannot be directly implemented. If the universe is nondeterministic, \(P =
\mathit{NP}\) may create two different classes of agents, subject to different
limitations.}%TODO think more before dashing off P=/=NP in a footnote.

Third, we require that the universe has a property called \textit{locality},
defined and discussed below. Locality requires that we introduce a notion of
time and a notion of space\footnotemark, which are developed in the same
section. The notion of locality described in this paper is very similar to the
concept as it is used in physics, but it is not precisely the same. Notably, it
allows universe-wide dynamic state, which is used in some interpretations of
quantum mechanics to escape the EPR paradox. For metaphysical reasons I do not
believe it is strictly necessary to provide an escape from the EPR paradox, but
it is certainly convenient that the theory can do so.

\footnotetext{This is why I am not examining a universe defined on a lambda
expression - I do not understand lambda calculus well enough to clearly define
time and especially space in such a context, although I suspect there is a way
to do it.}

Fourth, we assume that the universe is operating on random data for a time
interval \(t_\textit{hist} \gg t_l\), where \(t_l\) is the time interval over
which the agent under consideration has been operating.

Finally, we can without loss of generality disregard any halting state of the
universe, since the halting of the universe necessarily halts the agent or
agents embeded within.

%TODO maybe introduce a requirement that there be a degree of steady state in
%     the universe. Not totally sure how to formalize - maybe make agents LBAs
%     instead of full TMs, and then require that the universe be sufficiently
%     stable for them to arbitrarily extend their memory. Stability could also
%     be a requirement of agency - require that they be able to take actions
%     with effects 

\subsection{Space, Time, and Locality}
\label{sec:locality}

To develop the idea of space, we split the universe into two groups of
components: the infinite components and the finite components. The infinite
components form the universe's \textit{space}, and the finite components form
the universe's \textit{physics}. The space consists of a set of locations, which
can be alternately viewed as holding data or having a particular state. In a
Turing machine, the space is the Turing machine's tape, the locations are the
cells of that tape, and the state machine forms the physics.\footnotemark In a
cellular automaton, the cells once again form the space and the transition rule
defines the physics. In both cases, for each location, there is a finite set of
distinct locations to which it is considered \textit{adjacent}. These adjacency
lists define the geometry of the space, allowing us to construct a spatial
interval, alternately called a region - a subset of the universe's space where
the cells in the subset and their adjacency lists form a connected graph.
Finally, we define the distance from one cell to another as the length of the
shortest path along the adjacency graph connecting them. For our purposes, it
will suffice to define the size of a spatial interval \(s(\Delta x)\) as the
largest distance between two locations within the interval.

\footnotetext{The stateful physics of the Turing machine universe is an
uncomfortable quirk for me as a physicist. That said, this sort of global state
is a possible resolution to the EPR paradox (note: see if this can be easily
proved, or has been already), so I will not preemptively forbid it. Of course,
the time steps of the automaton universe (see below) are arguably another sort
of global state, or a repalacement of it, albiet in a less immediately apparant
way.}

Note that in defining the space we have ignored the contents of the space - the
state of the cells in the automaton or the symbols written on the tape in the
Turing machine. The potential contents of the space are an aspect of the
universe's physics. Furthermore, when we say that a spatial interval is
``known'' or ``specified'', we mean that the set of locations comprising it is
known or specified, but say nothing about the contents of the space.

%TODO write spatial interval and distance definitions in def environment

The universe's time can be defined in terms of the ``execution'' of the
universe. We take a configuration of the universe, called the initial state - a
list of live cells in the automaton, or a tape position, starting state, and
collection of tape data in the Turing machine - and apply the rules of the
universe's physics once. We then say that time has advanced one step or tick,
and the new configuration of the universe is called the result
state.\footnote{This discrete notion of time may or may not correspond to the
physical reality we inhabit, though it is expected to. Regardless, for reasons
discussed in Section \ref{sec:agents}, this should not affect the abstract
capabilities of agents embeded within the universe.} When we refer to the state
of the universe ``at'' a particular time step, we shall by convention be
referring to the initial state of that time step. We define a time interval
\(\Delta t\) as a sequence of time steps where for each step pair of steps
\(t_{i-1}\), \(t_i\) in \(\Delta t\), the initial state of step \(t_i\) is
identical to the result state of step \(t_{i-1}\).

%TODO write time interval definition(s) in def environment

%TODO discuss the arrow of time (maybe in footnote, maybe in next section)

We are now ready to define the property of locality:

\begin{defn}
   %TODO refine for readability; locality function should be in terms of regions
   %     not region sizes.

   A universe obeys the principle of \textit{locality} iff for any finite time
   interval \(\Delta t\) beginning at initial time \(t_0\) and ending at final
   time \(t_f\) and any finite space interval \(\Delta x\) we can define a
   finite space interval \(\Delta y\) for which knowledge of the spatial state
   of \(\Delta y\), as well as any universal state, at \(t_0\), in addition to
   knowledge of the universe's physics, is sufficient to predict the state in
   \(\Delta x\) at \(t_f\), and the size of \(\Delta y\) is a function of the
   size of \(\Delta x\), called the locality function \(L(s(\Delta x))\).

\end{defn}

\begin{lem}
   %TODO prove
   The locality function is bijective.
\end{lem}

If \(\Delta x\) is known and \(\Delta y\) is not, \(\Delta x\) is called the
\textit{region of interest} and \(\Delta y\) is called the \textit{region of
relevance}. If \(\Delta y\) is known and \(\Delta x\) is not, \(\Delta y\) is
called the \textit{known region} and \(\Delta x\) is called the
\textit{predictable region}. \(\Delta t\) is called the \textit{duration of
predictability}.

\begin{lem}
   %TODO prove
   The predictable region is always a subset of the known region.
\end{lem}

%TODO discuss relationship between locality and c.

%TODO discuss locality and c in TMs, automata.

%TODO import notions of spacelike, timelike, and lightlike intervals.

%TODO remove following paragraph (replaced by locality assumption and followon
%     discussion)
% Second, we assume that there is a maximum speed at which information
% propagates, which we call \(c\), the computation speed of the universe. This
% requires some notion of time in the universe. That is, we require that time pass
% consistently in all parts of the universe. Cellular automata necessarily possess
% this property, since every cell updates on every tick. Classical Turing Machines
% lack universal time; they have local time, in that the read/write head performs
% one operation on a cell each time the machine changes state, but a classical
% Turing Machine can operate on a cell, perform arbitrary operations on a
% different cell, and then propagate effects to the original cell. This allows
% arbitrary events to occur between each tick local to the cell.
%end of cut region

\subsection{Formal Definition of a Universe}
\label{sec:universe_formal}

% TODO pull everything together into a formal definition (likely will need
%      outside help for this)

\subsection{The Contents of a Spatial Region}
\label{sec:contents}

Having formally defined our universe, we now briefly turn to its contents at a
level more fundamental than the agent(s) it contains.

% TODO Describe how various properties of a region can be defined.

\section{Agency}
\label{sec:agents}

% TODO basic definition

% TODO rewrite for clarity; remove the words "extended" and "extension"
With a clear understanding of the universe in which our agent is to operate, we
can now proceed to define the agent itself. The agent is defined as a
deterministic linear bounded automaton or equivalent finite-memory reduced form
of a Turing equivalent structure\footnotemark extended with two operating
components and encoding in its memory two modelling components. Its program
includes of all of the code necessary to operate the extensions and process the
models, as well as code that would be able to operate a universal Turing
machine if given arbitrary memory. The operating components are a set of sensors
which deterministicly record changes to their state in the machine's memory and
a set of actuators which are able to deterministicly change the state of regions
outside the machine according to the internal state of the machine. The
modelling components are the world model, which is affected directly by the
operation of the sensors, and the approval relation, which is affected only by
the world model.

% TODO convert this footnote into a brief lemma.
\footnotetext{I conjecture that such a reduced form exists for any Turing
equivalent structure, but in any event many machine models exist which can
simulate or be simulated by a linearly bounded automaton of appropriate size.}

\subsection{World Models and Sensors}
\label{sec:models}

An agent's world model consists of two components: the state description and the
physical dynamics. The state description is a summary of the current state of
any part of the universe that can change when time is advanced. The physical
dynamics are a generic summary of how the universe's state changes as time is
advanced. Note that, for the Turing machine model of a universe, the current
state of the control automaton is part of the physics, but in the world model of
an agent in the universe that state is part of the broader state description,
and only its possible values are encoded in the physical dynamics.

\begin{thm}
   % TODO prove

   A perfect world model is insufficient to perfectly predict the future state
   of the universe.

\end{thm}

\begin{prf}
   % TODO from halting problem
\end{prf}

\begin{prf}
   % TODO from properties of the universe
\end{prf}

\begin{cor}
   An agent cannot perfectly predict itself.
\end{cor}

\begin{thm}
   % TODO prove

   No agent can acquire a complete state description.

\end{thm}

\begin{prf}
   % TODO from locality
\end{prf}

\begin{thm}
   % TODO prove

   A perfect model of the agent's knowable region is insufficient to perfectly
   predict the future state of the knowable region's corresponding predictable
   region.

\end{thm}

\begin{prf}
   % TODO from properties of the universe
\end{prf}

% notes: define fictional, plausible, and counterfactual statements
% see: Incomplete Models

\subsection{Approval Relations and Goal States}
\label{sec:goals}

% note: ARs are not utility functions; ARs can be contradictory. Talk about
%       converting ARs to utility functions.

% note: define the operation of goal resolution, implicit and explicit.

% note: talk about bounded and unbounded goals; the true nature of the utility
%       monster.

\subsection{Actuators and Extensions}
\label{sec:action}

\begin{lem}
% TODO prove

   An agent can use its actuators and sensors to, in finite time, modify an
   arbitrary region of space in its light cone to serve as an extension to its
   memory, enabling it to act as a Turing machine, as long as the agent's
   sensors are able to detect the results of the operation of its actuators.

\end{lem}

\begin{lem}
   % TODO prove

   An agent can use its actuators to, in finite time, construct additional
   actuators with arbitrary characteristics, so long as its actuators can
   modify distinct regions in different ways.

\end{lem}

\begin{lem}
   % TODO prove

   An agent can use its actuators to, in finite time, construct additional
   sensors with arbitrary characteristics, so long as its operating components
   meet the necessary conditions for the prior lemma.

\end{lem}

\section{Capability Metrics}
\label{sec:metrics}
% notes: three metrics: one for senses and prediction, one for planning and goal
%        resolution, and one for action economy.

We define three broad metrics to measure how well an agent is able to accomplish
its goals.

The first and most fundamental is action economy, which compares the time an
agent spends on a task to the degree to which the agent accomplishes said task.
It has many varients and specialized forms which can be used to measure things
like the intrinsic ability of an agent to affect its universe, the amount of
effort the agent spends on the task, and the cost to the agent in external
resources.

The simplest metric is the second, sensory acuity. It measures how much data the
agent recieves from its sensors relative to the amount of data the sensors
recieve from the universe.

The third and final metric is the agent's intelligence. Intelligence measures
the efficiency and efficacy of the agent's algorithms for various strictly
internal tasks, like updating the world model to account for new data, making
predictions based on the world model, performing goal resolution, and planning
courses of action. Intelligence can be divided into general and domain
intelligence depending on how well-defined the problem in question is.

%TODO see: Problems Tackled 2.1, 2.2; Omohundro Drives; Soars World Models

\section{Real-Time Strategy}
\label{sec:games}


\subsection{Personhood}
\label{sec:persons}


\subsection{Composite and Implicit Agents}
\label{sec:composites}

% It occurs to me that this section is going to show mathematically that
% political advocacy is at least moderately important as a cause area. Oh dear.

% note: discuss the "cast of millions" argument against artificial intelligence
%       and/or in favor of corporate intelligence.

% note: make fun of philosophers as a class.

\section{Future Work}
\label{sec:future}

\bibliographystyle{plain}
\bibliography{agency}
\end{document}
