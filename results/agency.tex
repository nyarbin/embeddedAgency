%Preamble
\documentclass[12pt]{article}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{commath}

\theoremstyle{definition}
\newtheorem{defn}{Definition}
\newtheorem{conj}{Conjecture}
\newtheorem{lem}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{prf}{Proof}

%Body
\begin{document}

\title{A Theory of Embeded Agency}
\author{Ben Reis\footnote{Imperfectly educated layman; embeded agent}}
\maketitle

\section{Introduction}
Much hay has been made over the hypothetical powers of artificial general
intelligence. In particular, a number of organizations and researchers have come
to endorse the position that a ``superintelligent'' AI will be constructed at
some point in the near future, and that measures must be taken to ensure that
said AI is ``friendly'', ie not likely to cause significant harm to humanity as
a whole.

The urgency of this task depends on the idea that ``intelligence'' is a
fundamentally unbounded property. That is, there is no maximally intelligent
mind and a mind (or some minds) capable of constructing other minds is capable
of constructing a mind that shares its goals but is more intelligent. The nature
of the task depends on the current nonexistence of any sort of superintelligent
AI and on the particular presumed form of any superintelligence that will emerge
in the future, namely that such an intelligence (and any successors it creates)
will be a single computer program, or possibly many copies of a single program,
implimented on a direct physical substrate.

However, at least as far as I can tell, relatively little work has been done to
check these assumptions. This is partially because of a difficulty in definition
- the fact that an agent must be embeded within the universe on which it acts
makes it difficult to rigorously define the problems an agent faces, and thence
prove limits on an agent's ability to solve them. In this paper I primarily wish
to define agency within a universe that has properties allowing the generated
results to apply to agents in the real world, without specifying the physics of
that universe more than necessary.

The definitions and results presented here, and any consequences thereof, I call
the theory of embeded agency. Embeded agency touches on a wide range of topics;
results from physics, game theory, decision theory, signal processing, and
classical machine learning and AI studies are likely to be useful in studying
this field. My hope is to provide a framework for synthesizing these results
into a realistic model of agency as it can be implemented in the real world.

\section{The Universe and its Properties}
\label{sec:universe}

We begin by defining the universe in which our agent will act. This will be
where most of our assumptions are located; the applicability of the results in
this paper depends on the defined universe matching up to our own as to the
effects of its properties on the capabilities of an agent embeded within it. I
will occasionally refer in this section to the agent or agents embeded within
the universe; these will be defined in Section \ref{sec:agents}.

The first and most fundamental assumption is that the universe is a universal
Turing machine or Turing equivalent construct - that is, a mathematical
construct capable of simulating Turing machines - but \textit{not} a more
powerful construct such as a hypercomputer, and not a construct with distinct
capabilities like a real computer\footnote{That the universe is not a real
computer depends on the holographic principle being a physical law. This is
widely suspected but not confirmed, and would forbid certain solutions to
general relativity, the implications of which are an unsolved problem in quantum
gravity.}. In the remainder of this section, I will examine a classical Turing
machine\footnote{5-tuple, two-way tape model; all instructions must move one
space left or right. Other models complicate some of the locality-related
notions discussed below.} and a Turing complete cellular automaton and determine
how these classes must be restricted, if necessary, to conform to our remaining
axiomatic properties. I find the cellular automaton's conformance to the axioms
to be more intuitive\footnotemark, but it may be easier to prove properties of
agents with respect to a Turing machine universe. The violation of these axioms
will be addressed briefly below but are not a focus of this paper.

\footnotetext{In general I find the intuitive conformance of cellular automata
to certain axioms of physics, and the existance of \textit{Day and Night}, a
Life-like rule that appears to exhibit a kind of charge symmetry, to be highly
suggestive in a physics context, but I lack the background to effectively
examine the implications. \cite{moriceau2011}, \cite{wacker2016}, and the works
they cite appear to be useful places to start when examining the idea of a
cellular automaton (perhaps somewhat generalized) that generates known laws of
physics.}

Second, we assume that the universe is deterministic. This is largely to
simplify certain ideas discussed in Section \ref{sec:models}, but the
implications of a nondeterministic universe should be examined at some point.

Third, we require that the universe has a property called \textit{locality}.
Locality requires that we introduce a notion of time and a notion of
space.\footnote{This is why I am not examining a universe defined on a lambda
expression - I do not understand lambda calculus well enough to clearly define
time and especially space in such a context.}

To develop the idea of space, we split the universe into two groups of
components: the infinite components and the finite components. The infinite
components form the universe's \textit{space}, and the finite components form
the universe's \textit{physics}. The space consists of a set of locations, which
can be alternately viewed as holding data or having a particular state. In a
Turing machine, the space is the Turing machine's tape, the locations are the
cells of that tape, and the state machine forms the physics.\footnotemark In a
cellular automaton, the cells once again form the space and the transition rule
defines the physics. In both cases, for each location, there is a finite set of
distinct locations to which it is considered \textit{adjacent}. These adjacency
lists define the geometry of the space, allowing us to construct a spatial
interval, alternately called a region - a subset of the universe's space where
the cells in the subset and their adjacency lists form a connected graph.
Finally, we define the distance from one cell to another as the length of the
shortest path along the adjacency graph connecting them. For our purposes, it
will suffice to define the size of a spatial interval \(s(\Delta x)\) as the
largest distance between two locations within the interval.

\footnotetext{The stateful physics of the Turing machine universe is an
uncomfortable quirk for me as a physicist. That said, this sort of global state
is a possible resolution to the EPR paradox (note: see if this can be easily
proved, or has been already), so I will not preemptively forbid it. Of course,
the time steps of the automaton universe (see below) are arguably another sort
of global state, or a repalacement of it, albiet in a less immediately apparant
way.}

Note that in defining the space we have ignored the contents of the space - the
state of the cells in the automaton or the symbols written on the tape in the
Turing machine. The potential contents of the space are an aspect of the
universe's physics. Furthermore, when we say that a spatial interval is
``known'' or ``specified'', we mean that the set of locations comprising it is
known or specified, but say nothing about the contents of the space.

%TODO write spatial interval and distance definitions in def environment

The universe's time can be defined in terms of the ``execution'' of the
universe. We take a configuration of the universe, called the initial state - a
list of live cells in the automaton, or a tape position, starting state, and
collection of tape data in the Turing machine - and apply the rules of the
universe's physics once. We then say that time has advanced one step or tick,
and the new configuration of the universe is called the result
state.\footnote{This discrete notion of time may or may not correspond to the
physical reality we inhabit, though it is expected to. Regardless, for reasons
discussed in Section \ref{sec:agents}, this should not affect the abstract
capabilities of agents embeded within the universe.} When we refer to the state
of the universe ``at'' a particular time step, we shall by convention be
referring to the initial state of that time step. We define a time interval
\(\Delta t\) as a sequence of time steps where for each step pair of steps
\(t_{i-1}\), \(t_i\) in \(\Delta t\), the initial state of step \(t_i\) is
identical to the result state of step \(t_{i-1}\).

%TODO write time interval definition(s) in def environment

%TODO discuss the arrow of time (maybe in footnote, maybe in next section)

We are now ready to define the property of locality:

\begin{defn}
   %TODO refine for readability

   A universe obeys the principle of \textit{locality} iff for any finite time
   interval \(\Delta t\) beginning at initial time \(t_0\) and ending at final
   time \(t_f\) and any finite space interval \(\Delta x\) we can define a
   finite space interval \(\Delta y\) for which knowledge of the spatial state
   of \(\Delta y\), as well as any universal state, at \(t_0\), in addition to
   knowledge of the universe's physics, is sufficient to predict the state in
   \(\Delta x\) at \(t_f\), and the size of \(\Delta y\) is a function of the
   size of \(\Delta x\), called the locality function \(L(s(\Delta x))\).

\end{defn}

If \(\Delta x\) is known and \(\Delta y\) is not, \(\Delta x\) is called the
\textit{region of interest} and \(\Delta y\) is called the \textit{region of
relevance}. If \(\Delta y\) is known and \(\Delta x\) is not, \(\Delta y\) is
called the \textit{known region} and \(\Delta x\) is called the
\textit{predictable region}. \(\Delta t\) is called the \textit{duration of
predictability}.

%TODO discuss relationship between locality and c.

%TODO discuss locality and c in TMs, automata.

%TODO import notions of spacelike, timelike, and lightlike intervals.

%TODO remove following paragraph
% Second, we assume that there is a maximum speed at which information
% propagates, which we call \(c\), the computation speed of the universe. This
% requires some notion of time in the universe. That is, we require that time pass
% consistently in all parts of the universe. Cellular automata necessarily possess
% this property, since every cell updates on every tick. Classical Turing Machines
% lack universal time; they have local time, in that the read/write head performs
% one operation on a cell each time the machine changes state, but a classical
% Turing Machine can operate on a cell, perform arbitrary operations on a
% different cell, and then propagate effects to the original cell. This allows
% arbitrary events to occur between each tick local to the cell.
%end of cut region

Fourth, we assume that the universe is operating on random data for a time
interval \(t_\textit{hist} \gg t_l\), where \(t_l\) is the time interval over
which the agent under consideration has been operating.

Finally, we can without loss of generality disregard any halting state of the
universe, since the halting of the universe necessarily halts the agent or
agents embeded within.

%TODO maybe introduce a requirement that there be a degree of steady state in
%     the universe. Not totally sure how to formalize - maybe make agents LBAs
%     instead of full TMs, and then require that the universe be sufficiently
%     stable for them to arbitrarily extend their memory. Stability could also
%     be a requirement of agency - require that they be able to take actions
%     with effects 

\section{Agency}
\label{sec:agents}

% TODO basic definition

\subsection{World Models}
\label{sec:models}

% notes: define fictional, plausible, and counterfactual statements
% see: Incomplete Models

\subsection{Approval Relations and Goal States}
\label{sec:goals}

% note: ARs are not utility functions; ARs can be contradictory. Talk about
%       converting ARs to utility functions.

% note: define the operation of goal resolution, implicit and explicit.

\subsection{Capability Metrics}
\label{sec:metrics}

% notes: three metrics: one for senses and prediction, one for planning and goal
%        resolution, and one for action economy.

%TODO may absorb next section

\section{Intelligence, Naturalized Induction, and Interaction}
\label{sec:intelligence}

%TODO see: Problems Tackled 2.1, 2.2; Omohundro Drives; Soars World Models

\section{Real-Time Strategy}
\label{sec:games}


\section{Personhood}
\label{sec:persons}


\section{Composite and Implicit Agents}
\label{sec:composites}

% note: discuss the "cast of millions" argument against artificial intelligence
%       and/or in favor of corporate intelligence.

% note: make fun of philosophers as a class.

\section{Future Work}
\label{sec:future}

\bibliographystyle{plain}
\bibliography{agency}
\end{document}
